Large CSV Ingestion into MySQL Using Git Bash / CMD

(Portfolio Project â€“ Command-Based Workflow)

# ------------------------------------------------------------
# STEP 0: Open Git Bash or CMD
# ------------------------------------------------------------
# Navigate is optional; MySQL is started directly using full path

# ------------------------------------------------------------
# STEP 1: Start MySQL with LOCAL INFILE enabled
# ------------------------------------------------------------
"/c/Program Files/MySQL/MySQL Server 8.0/bin/mysql.exe" --local-infile=1 -u root -p

-- ------------------------------------------------------------
-- STEP 2: Enable and verify local file loading
-- ------------------------------------------------------------
SET GLOBAL local_infile = 1;
SHOW VARIABLES LIKE 'local_infile';

-- ------------------------------------------------------------
-- STEP 3: Use portfolio database
-- (Database was created earlier in MySQL Workbench)
-- ------------------------------------------------------------
USE portfolio_project;

-- ------------------------------------------------------------
-- STEP 4: Create table - covid_deaths
-- Schema defined before import to control data types
-- ------------------------------------------------------------
CREATE TABLE covid_deaths (
    iso_code VARCHAR(10),
    continent VARCHAR(50),
    location VARCHAR(100),
    population DOUBLE,
    date DATE,
    total_cases DOUBLE,
    new_cases DOUBLE,
    new_cases_smoothed DOUBLE,
    total_deaths DOUBLE,
    new_deaths DOUBLE,
    new_deaths_smoothed DOUBLE,
    total_cases_per_million DOUBLE,
    new_cases_per_million DOUBLE,
    new_cases_smoothed_per_million DOUBLE,
    total_deaths_per_million DOUBLE,
    new_deaths_per_million DOUBLE,
    new_deaths_smoothed_per_million DOUBLE,
    reproduction_rate DOUBLE,
    icu_patients DOUBLE,
    icu_patients_per_million DOUBLE,
    hosp_patients DOUBLE,
    hosp_patients_per_million DOUBLE,
    weekly_icu_admissions DOUBLE,
    weekly_icu_admissions_per_million DOUBLE,
    weekly_hosp_admissions DOUBLE,
    weekly_hosp_admissions_per_million DOUBLE
);

-- ------------------------------------------------------------
-- STEP 5: Create table - covid_vaccinations
-- ------------------------------------------------------------
CREATE TABLE covid_vaccinations (
    iso_code VARCHAR(10),
    continent VARCHAR(50),
    location VARCHAR(100),
    date DATE,
    new_tests DOUBLE,
    total_tests DOUBLE,
    total_tests_per_thousand DOUBLE,
    new_tests_per_thousand DOUBLE,
    new_tests_smoothed DOUBLE,
    new_tests_smoothed_per_thousand DOUBLE,
    positive_rate DOUBLE,
    tests_per_case DOUBLE,
    tests_units VARCHAR(50),
    total_vaccinations DOUBLE,
    people_vaccinated DOUBLE,
    people_fully_vaccinated DOUBLE,
    new_vaccinations DOUBLE,
    new_vaccinations_smoothed DOUBLE,
    total_vaccinations_per_hundred DOUBLE,
    people_vaccinated_per_hundred DOUBLE,
    people_fully_vaccinated_per_hundred DOUBLE,
    new_vaccinations_smoothed_per_million DOUBLE,
    stringency_index DOUBLE,
    population_density DOUBLE,
    median_age DOUBLE,
    aged_65_older DOUBLE,
    aged_70_older DOUBLE,
    gdp_per_capita DOUBLE,
    extreme_poverty DOUBLE,
    cardiovasc_death_rate DOUBLE,
    diabetes_prevalence DOUBLE,
    female_smokers DOUBLE,
    male_smokers DOUBLE,
    handwashing_facilities DOUBLE,
    hospital_beds_per_thousand DOUBLE,
    life_expectancy DOUBLE,
    human_development_index DOUBLE
);

-- ------------------------------------------------------------
-- STEP 6: Load CovidDeaths.csv (explicit column mapping + date parsing)
-- ------------------------------------------------------------
LOAD DATA LOCAL INFILE
'C:/Users/ACER/OneDrive/Desktop/my_projects/SQL/Covid-Death-and-Vaccination-Analysis/CovidDeaths.csv'
INTO TABLE covid_deaths
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(
 iso_code, continent, location, population, @date,
 total_cases, new_cases, new_cases_smoothed,
 total_deaths, new_deaths, new_deaths_smoothed,
 total_cases_per_million, new_cases_per_million,
 new_cases_smoothed_per_million,
 total_deaths_per_million, new_deaths_per_million,
 new_deaths_smoothed_per_million, reproduction_rate,
 icu_patients, icu_patients_per_million,
 hosp_patients, hosp_patients_per_million,
 weekly_icu_admissions, weekly_icu_admissions_per_million,
 weekly_hosp_admissions, weekly_hosp_admissions_per_million
)
SET date = STR_TO_DATE(@date, '%Y-%m-%d');

-- ------------------------------------------------------------
-- STEP 7: Load CovidVaccinations.csv (same ingestion method)
-- ------------------------------------------------------------
LOAD DATA LOCAL INFILE
'C:/Users/ACER/OneDrive/Desktop/my_projects/SQL/Covid-Death-and-Vaccination-Analysis/CovidVaccinations.csv'
INTO TABLE covid_vaccinations
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(
 iso_code, continent, location, @date,
 new_tests, total_tests, total_tests_per_thousand,
 new_tests_per_thousand, new_tests_smoothed,
 new_tests_smoothed_per_thousand, positive_rate,
 tests_per_case, tests_units,
 total_vaccinations, people_vaccinated,
 people_fully_vaccinated, new_vaccinations,
 new_vaccinations_smoothed,
 total_vaccinations_per_hundred,
 people_vaccinated_per_hundred,
 people_fully_vaccinated_per_hundred,
 new_vaccinations_smoothed_per_million,
 stringency_index, population_density, median_age,
 aged_65_older, aged_70_older, gdp_per_capita,
 extreme_poverty, cardiovasc_death_rate,
 diabetes_prevalence, female_smokers, male_smokers,
 handwashing_facilities, hospital_beds_per_thousand,
 life_expectancy, human_development_index
)
SET date = STR_TO_DATE(@date, '%Y-%m-%d');

-- ------------------------------------------------------------
-- STEP 8: Verify successful ingestion
-- ------------------------------------------------------------
SELECT COUNT(*) FROM covid_deaths;
SELECT COUNT(*) FROM covid_vaccinations;

SELECT * FROM covid_deaths LIMIT 10;
SELECT * FROM covid_vaccinations LIMIT 10;

-- ------------------------------------------------------------
-- END
-- Large CSV files successfully ingested using CMD/Git Bash
-- Data ready for analytical SQL queries
-- ------------------------------------------------------------
