Large CSV File Upload into MySQL Using CMD

(My Portfolio Project Ingestion Process)

This document explains how I uploaded large CSV files into MySQL using Command Prompt (CMD) for my portfolio project.

Database was created in MySQL Workbench

All remaining steps were executed via CMD

Data source: https://ourworldindata.org/covid-deaths

Step 1: Start MySQL from CMD with Local File Support
"C:\Program Files\MySQL\MySQL Server 8.0\bin\mysql.exe" --local-infile=1 -u root -p

Step 2: Enable and Verify Local File Loading
SET GLOBAL local_infile = 1;
SHOW VARIABLES LIKE 'local_infile';


Expected result:

local_infile | ON

Step 3: Use Portfolio Database
USE portfolio_project;

Step 4: Create Tables (Schema Defined Before Import)
Table: covid_deaths
CREATE TABLE covid_deaths (
    iso_code VARCHAR(10),
    continent VARCHAR(50),
    location VARCHAR(100),
    population DOUBLE,
    date DATE,
    total_cases DOUBLE,
    new_cases DOUBLE,
    new_cases_smoothed DOUBLE,
    total_deaths DOUBLE,
    new_deaths DOUBLE,
    new_deaths_smoothed DOUBLE,
    total_cases_per_million DOUBLE,
    new_cases_per_million DOUBLE,
    new_cases_smoothed_per_million DOUBLE,
    total_deaths_per_million DOUBLE,
    new_deaths_per_million DOUBLE,
    new_deaths_smoothed_per_million DOUBLE,
    reproduction_rate DOUBLE,
    icu_patients DOUBLE,
    icu_patients_per_million DOUBLE,
    hosp_patients DOUBLE,
    hosp_patients_per_million DOUBLE,
    weekly_icu_admissions DOUBLE,
    weekly_icu_admissions_per_million DOUBLE,
    weekly_hosp_admissions DOUBLE,
    weekly_hosp_admissions_per_million DOUBLE
);

Table: covid_vaccinations
CREATE TABLE covid_vaccinations (
    iso_code VARCHAR(10),
    continent VARCHAR(50),
    location VARCHAR(100),
    date DATE,
    new_tests DOUBLE,
    total_tests DOUBLE,
    total_tests_per_thousand DOUBLE,
    new_tests_per_thousand DOUBLE,
    new_tests_smoothed DOUBLE,
    new_tests_smoothed_per_thousand DOUBLE,
    positive_rate DOUBLE,
    tests_per_case DOUBLE,
    tests_units VARCHAR(50),
    total_vaccinations DOUBLE,
    people_vaccinated DOUBLE,
    people_fully_vaccinated DOUBLE,
    new_vaccinations DOUBLE,
    new_vaccinations_smoothed DOUBLE,
    total_vaccinations_per_hundred DOUBLE,
    people_vaccinated_per_hundred DOUBLE,
    people_fully_vaccinated_per_hundred DOUBLE,
    new_vaccinations_smoothed_per_million DOUBLE,
    stringency_index DOUBLE,
    population_density DOUBLE,
    median_age DOUBLE,
    aged_65_older DOUBLE,
    aged_70_older DOUBLE,
    gdp_per_capita DOUBLE,
    extreme_poverty DOUBLE,
    cardiovasc_death_rate DOUBLE,
    diabetes_prevalence DOUBLE,
    female_smokers DOUBLE,
    male_smokers DOUBLE,
    handwashing_facilities DOUBLE,
    hospital_beds_per_thousand DOUBLE,
    life_expectancy DOUBLE,
    human_development_index DOUBLE
);

Step 5: Load Large CSV Files (Same Method for Both Tables)
Load CovidDeaths.csv
LOAD DATA LOCAL INFILE
'C:/Users/ACER/OneDrive/Desktop/my_projects/SQL/Covid-Death-and-Vaccination-Analysis/CovidDeaths.csv'
INTO TABLE covid_deaths
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(
 iso_code, continent, location, population, @date,
 total_cases, new_cases, new_cases_smoothed,
 total_deaths, new_deaths, new_deaths_smoothed,
 total_cases_per_million, new_cases_per_million,
 new_cases_smoothed_per_million,
 total_deaths_per_million, new_deaths_per_million,
 new_deaths_smoothed_per_million, reproduction_rate,
 icu_patients, icu_patients_per_million,
 hosp_patients, hosp_patients_per_million,
 weekly_icu_admissions, weekly_icu_admissions_per_million,
 weekly_hosp_admissions, weekly_hosp_admissions_per_million
)
SET date = STR_TO_DATE(@date, '%Y-%m-%d');

Load CovidVaccinations.csv
LOAD DATA LOCAL INFILE
'C:/Users/ACER/OneDrive/Desktop/my_projects/SQL/Covid-Death-and-Vaccination-Analysis/CovidVaccinations.csv'
INTO TABLE covid_vaccinations
FIELDS TERMINATED BY ','
ENCLOSED BY '"'
LINES TERMINATED BY '\r\n'
IGNORE 1 LINES
(
 iso_code, continent, location, @date,
 new_tests, total_tests, total_tests_per_thousand,
 new_tests_per_thousand, new_tests_smoothed,
 new_tests_smoothed_per_thousand, positive_rate,
 tests_per_case, tests_units,
 total_vaccinations, people_vaccinated,
 people_fully_vaccinated, new_vaccinations,
 new_vaccinations_smoothed,
 total_vaccinations_per_hundred,
 people_vaccinated_per_hundred,
 people_fully_vaccinated_per_hundred,
 new_vaccinations_smoothed_per_million,
 stringency_index, population_density, median_age,
 aged_65_older, aged_70_older, gdp_per_capita,
 extreme_poverty, cardiovasc_death_rate,
 diabetes_prevalence, female_smokers, male_smokers,
 handwashing_facilities, hospital_beds_per_thousand,
 life_expectancy, human_development_index
)
SET date = STR_TO_DATE(@date, '%Y-%m-%d');

Step 6: Verify Successful Ingestion
SELECT COUNT(*) FROM covid_deaths;
SELECT COUNT(*) FROM covid_vaccinations;

SELECT * FROM covid_deaths LIMIT 10;
SELECT * FROM covid_vaccinations LIMIT 10;

Final Notes

Large CSV files were imported using CMD + LOAD DATA LOCAL INFILE

Same ingestion strategy applied to both datasets

Table schemas were defined explicitly to avoid datatype issues

Full row and column ingestion verified successfully

Data was then ready for analytical SQL queries
